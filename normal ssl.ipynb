{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec74dc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './pyLDLE2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "488354b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib.get_backend() =  module://matplotlib_inline.backend_inline\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pyLDLE2 import util_, visualize_, datasets\n",
    "from scipy import sparse as sp\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy import optimize\n",
    "from scipy.special import erf, erfinv\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']\n",
    "\n",
    "from scipy.stats import chi2\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import graphlearning as gl\n",
    "\n",
    "import bx_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b578e366",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = gl.datasets.load('mnist', metric='raw')\n",
    "data = data - data.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c267f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_opts = {\n",
    "    'd': 2,\n",
    "    'k_nn': 10,\n",
    "    'k_tune': 10,\n",
    "    'ds': False,\n",
    "    'p': 0.99,\n",
    "    'h': 1.0,\n",
    "    's': 0.3,\n",
    "    'local_pca': False,\n",
    "    'newton_maxiter': 1000\n",
    "}\n",
    "\n",
    "\n",
    "def estimate_mu(X, opts=default_opts):\n",
    "    d = opts['d']\n",
    "    h = opts['h']\n",
    "    ds = opts['ds']\n",
    "    \n",
    "    # compute nearest neighbors\n",
    "    neigh_dist, neigh_ind = util_.nearest_neighbors(X, opts['k_nn'], metric='euclidean')\n",
    "    neigh_dist = neigh_dist[:,1:]\n",
    "    neigh_ind = neigh_ind[:,1:]\n",
    "    \n",
    "    # set h\n",
    "    if h <= 0:\n",
    "        h_cand = np.sqrt(2)*neigh_dist[:,opts['k_tune']-2]/np.sqrt(chi2.ppf(opts['p'], df=d))\n",
    "        h = np.min(h_cand)\n",
    "        \n",
    "    print('h:', h, flush=True)\n",
    "    \n",
    "    # standard kernel\n",
    "    K = np.exp(-neigh_dist**2/h**2)\n",
    "    n = X.shape[0]\n",
    "    source_ind = np.repeat(np.arange(n),neigh_ind.shape[1])\n",
    "    K = coo_matrix((K.flatten(),(source_ind, neigh_ind.flatten())),shape=(n,n))\n",
    "    ones_K_like = coo_matrix((np.ones(neigh_dist.shape).flatten(),(source_ind, neigh_ind.flatten())),shape=(n,n))\n",
    "\n",
    "    # symmetrize the kernel\n",
    "    K = K + K.T\n",
    "    ones_K_like = ones_K_like + ones_K_like.T\n",
    "    K.data /= ones_K_like.data\n",
    "    \n",
    "    # if doubly stochastic\n",
    "    if ds:\n",
    "        s = opts['s']\n",
    "        K = K.tocoo()\n",
    "        K, D = sinkhorn(K)\n",
    "        K = K.tocsr()\n",
    "        print('s:', s, flush=True)\n",
    "    else:\n",
    "        D = None\n",
    "    \n",
    "    # Compute ||mu_i||\n",
    "\n",
    "    mu_norm = np.zeros_like(X)\n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        if opts['local_pca']:\n",
    "            X_i_nbrs = X[neigh_ind[i,:].tolist()+[i],:]\n",
    "            pca = PCA(n_components=d)\n",
    "            y = pca.fit_transform(X_i_nbrs)\n",
    "            X_rec = pca.inverse_transform(y)\n",
    "            temp = X_rec[:-1,:] - X_rec[-1,:][None,:]\n",
    "        else:\n",
    "            temp = X[neigh_ind[i,:],:]-X[i,:][None,:]\n",
    "            \n",
    "        if ds:\n",
    "            mu_norm[i] = K.getrow(i).power(s)[0,neigh_ind[i,:]].dot(temp)\n",
    "        else:\n",
    "            mu_norm[i] = K.getrow(i)[0,neigh_ind[i,:]].dot(temp)\n",
    "    \n",
    "    return K, mu_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ba94c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h: 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c086d3d32c40868f054036b530257d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "W, mu = estimate_mu(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7f968fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nFor SSL, we solve the problem\\n\\\\min_X { tr(X^T L X) = \\\\sum_i w_{ij} ||X_i - X_j||^2 } s.t. X_i = Y_i on the labels\\n\\nWhen the number of labels is small, we solve the related problem\\n\\\\min_X { tr(X^T L X) = \\\\sum_i w_{ij} ||X_i - X_j||^2 } s.t. X_i = Y_i, 1^T X = 0\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"We compare: SSL using\n",
    "(1.) the canonical heat kernel\n",
    "(2.) the ds kernel\n",
    "(3.) canonical kernel + normal info\n",
    "(4.) ds kernel + normal info \"\"\"\n",
    "\n",
    "\"\"\" \n",
    "For SSL, we solve the problem\n",
    "\\min_X { tr(X^T L X) = \\sum_i w_{ij} ||X_i - X_j||^2 } s.t. X_i = Y_i on the labels\n",
    "\n",
    "When the number of labels is small, we solve the related problem\n",
    "\\min_X { tr(X^T L X) = \\sum_i w_{ij} ||X_i - X_j||^2 } s.t. X_i = Y_i, 1^T X = 0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef476e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"subsample labels \"\"\"\n",
    "num_train_per_class = 10\n",
    "train_ind = gl.trainsets.generate(labels, rate=num_train_per_class)\n",
    "train_labels = labels[train_ind]\n",
    "F = gl.utils.labels_to_onehot(train_labels) # to one-hot labels\n",
    "k = F.shape[1]\n",
    "\n",
    "#Locations of unlabeled points\n",
    "n = data.shape[0]\n",
    "idx = np.full((n,), True, dtype=bool)\n",
    "idx[train_ind] = False\n",
    "\n",
    "# compute Laplacian\n",
    "D = sp.spdiags((W * np.ones(n)), 0, n, n)\n",
    "L = D - W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaacaf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjgrad(A, b, x0=None, max_iter=1e5, tol=1e-5):\n",
    "    \"\"\"Conjugate Gradient Method to solve Ax = B \"\"\"\n",
    "    x = np.zeros_like(b)\n",
    "\n",
    "    r = b - A@x\n",
    "    p = r\n",
    "    rsold = np.sum(r**2,axis=0)\n",
    "  \n",
    "    err = 1 \n",
    "    i = 0\n",
    "    while (err > tol) and (i < max_iter):\n",
    "        i += 1\n",
    "        Ap = A@p\n",
    "        alpha = rsold / np.sum(p*Ap,axis=0)\n",
    "        x += alpha * p\n",
    "        r -= alpha * Ap\n",
    "        rsnew = np.sum(r**2,axis=0)\n",
    "        err = np.sqrt(np.sum(rsnew)) \n",
    "        p = r + (rsnew / rsold) * p\n",
    "        rsold = rsnew\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dbb3a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Right hand side\n",
    "b = -L[:,train_ind]*F\n",
    "b = b[idx,:]\n",
    "\n",
    "#Left hand side matrix\n",
    "A = L[idx,:]\n",
    "A = A[:,idx]\n",
    "\n",
    "#Preconditioner\n",
    "m = A.shape[0]\n",
    "M = A.diagonal()\n",
    "M = sp.spdiags(1/np.sqrt(M+1e-10),0,m,m).tocsr()\n",
    "\n",
    "v = conjgrad(M*A*M, M*b)\n",
    "v = M*v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28ed36d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 64.769%\n"
     ]
    }
   ],
   "source": [
    "#Add labels back into array\n",
    "u = np.zeros((n,k))\n",
    "u[idx,:] = v\n",
    "u[train_ind,:] = F\n",
    "\n",
    "pred_labels = u.argmax(1)\n",
    "accuracy = np.mean(pred_labels == labels)\n",
    "print(f'accuracy: {accuracy*100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4adaa120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphlearning import weightmatrix\n",
    "\n",
    "def reweight_kernel(X, mu, r=10):\n",
    "    #KNN info\n",
    "    J,D = weightmatrix.knnsearch(X,r)\n",
    "    \n",
    "    #Normalize to unit norm\n",
    "    norms = np.sqrt(np.sum(mu*mu,axis=1))\n",
    "    mu = mu/norms[:,np.newaxis]\n",
    "    \n",
    "    V = X[:,np.newaxis,:] - X[J] #(x^0-x^i), nxkxd array\n",
    "    \n",
    "    # vector projection onto normals\n",
    "    adotb = (V*mu[:,np.newaxis,:]).sum(-1)\n",
    "    aprojb = adotb[:,:,np.newaxis] * (mu[:, np.newaxis])\n",
    "    \n",
    "    h=1.0\n",
    "    weights = np.exp(-np.linalg.norm(aprojb, axis=-1)**2/h**2)\n",
    "    \n",
    "    #Flatten knn data and weights\n",
    "    knn_ind = J.flatten()\n",
    "    weights = weights.flatten()\n",
    "    \n",
    "    #Self indices\n",
    "    self_ind = np.ones((n,r))*np.arange(n)[:,None]\n",
    "    self_ind = self_ind.flatten()\n",
    "    \n",
    "    #Construct sparse matrix and symmetric normalization\n",
    "    W = sp.coo_matrix((weights, (self_ind, knn_ind)),shape=(n,n)).tocsr()\n",
    "    W = (W + W.transpose())/2;\n",
    "    W.setdiag(0)\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cfe9b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wr = reweight_kernel(data, -mu)\n",
    "\n",
    "# compute Laplacian\n",
    "Dr = sp.spdiags((Wr * np.ones(n)), 0, n, n)\n",
    "Lr = Dr - Wr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c385f5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Right hand side\n",
    "b = -Lr[:,train_ind]*F\n",
    "b = b[idx,:]\n",
    "\n",
    "#Left hand side matrix\n",
    "A = Lr[idx,:]\n",
    "A = A[:,idx]\n",
    "\n",
    "#Preconditioner\n",
    "m = A.shape[0]\n",
    "M = A.diagonal()\n",
    "M = sp.spdiags(1/np.sqrt(M+1e-10),0,m,m).tocsr()\n",
    "\n",
    "v = conjgrad(M*A*M, M*b)\n",
    "v = M*v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97d65277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 70.469%\n"
     ]
    }
   ],
   "source": [
    "#Add labels back into array\n",
    "u = np.zeros((n,k))\n",
    "u[idx,:] = v\n",
    "u[train_ind,:] = F\n",
    "\n",
    "pred_labels = u.argmax(1)\n",
    "accuracy = np.mean(pred_labels == labels)\n",
    "print(f'accuracy: {accuracy*100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1792383c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
